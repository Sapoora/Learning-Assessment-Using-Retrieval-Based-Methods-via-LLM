{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzRzkp6gS4-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808873d6-a765-47a4-b1f9-d2d535182f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain\\\n",
        "    langchain-community\\\n",
        "    langchain-together\\\n",
        "    langchain-core\\\n",
        "    faiss-cpu\\\n",
        "    faiss-gpu\\\n",
        "    sentence-transformers\\\n",
        "    pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PJSHWJbTCxN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_together import ChatTogether\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Literal\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from IPython.core.display import Markdown\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.document_loaders import PyMuPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCTA9J-jTUTZ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOGETHER_API_KEY\"] = \"c831603b49af1a3eaf681514d22fd8af442f6790b490d463d351d5c318ad2540\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy4zZyMpTUx2"
      },
      "outputs": [],
      "source": [
        "# Loading the ruleset file\n",
        "\n",
        "pdf_file_paths = [\n",
        "    \"/content/sample_reports/RM1_4022_HW2_22.pdf\" #\n",
        "]\n",
        "\n",
        "documents = []\n",
        "for pdf_file in pdf_file_paths:\n",
        "    if pdf_file in pdf_file_paths:\n",
        "        loader = PyMuPDFLoader(file_path=pdf_file)\n",
        "        l = loader.load()\n",
        "        documents.extend(l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_PN9KqxT1uZ"
      },
      "source": [
        "### retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KEhafdkT5U6"
      },
      "source": [
        "retriever is not used in this proof of concept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki_jM2-BTiRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "b1359ba4-df97-4ad2-ca37-8bb8220f88c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-128-32b82e04eb42>:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  embedding_function = HuggingFaceEmbeddings(show_progress=True, multi_process=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-32b82e04eb42>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_splitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membedding_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCrossEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"CrossEncoder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPushToHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentenceEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/evaluation/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mBinaryClassificationEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mEmbeddingSimilarityEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbeddingSimilarityEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mInformationRetrievalEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInformationRetrievalEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mLabelAccuracyEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelAccuracyEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mMSEEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSEEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/evaluation/BinaryClassificationEvaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaired_cosine_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaired_euclidean_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaired_manhattan_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m from ._classification import (\n\u001b[1;32m      9\u001b[0m     \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mv_measure_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0;31m from ._unsupervised import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcalinski_harabasz_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdavies_bouldin_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidate_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VALID_METRICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise_distances_chunked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pairwise_distances_reduction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgKmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pairwise_fast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_chi2_kernel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sparse_manhattan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m from ._dispatcher import (\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mArgKmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mArgKminClassMode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mArgKmin64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m from ._argkmin_classmode import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mArgKminClassMode32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mArgKminClassMode64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_argkmin_classmode.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36minit sklearn.metrics._pairwise_distances_reduction._argkmin_classmode\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "embedding_function = HuggingFaceEmbeddings(show_progress=True, multi_process=True)\n",
        "vector_store = FAISS.from_documents(documents=chunks, embedding=embedding_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVYd6RkiTiMl",
        "outputId": "4ccdf88f-c40a-4520-c3db-aaf6fd0ed3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rank_bm25\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGYFwDmqTiJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "06701f26-705a-40c6-9730-901060aa90af"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1e4b85391124>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbm25_retriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBM25Retriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfaiss_retriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m retriever = EnsembleRetriever(\n\u001b[1;32m      4\u001b[0m     \u001b[0mretrievers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbm25_retriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_retriever\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/retrievers/bm25.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, bm25_params, preprocess_func, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mBM25Retriever\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         return cls.from_texts(\n\u001b[1;32m     90\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ],
      "source": [
        "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
        "faiss_retriever = vector_store.as_retriever()\n",
        "retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, faiss_retriever],\n",
        "    weights=[0.25, 0.75]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm5xtVbHUWoS"
      },
      "source": [
        "we can now define a query and use the retriever to retrieve.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaNqSm1yTiFr",
        "outputId": "3f68fd26-daff-4932-ca92-aff39dbcb8f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='application ھﺎﯾﯽ ﮐﮫ ﻗﺎﺑﻞ اﺳﺘﻔﺎده ھﺴﺘﻨﺪ ذﮐﺮ ﺷﻮﻧﺪ.ﺑﮫ طﻮر ﻣﺜﺎل \\n \\nداده ھﺎی ﺧﺎم و داده ھﺎی ﭘﺮدازش ﺷﺪه ﺑﺎﯾﺪ در reuslt ﺑﺎﺷﻦ و ﻧﮫ .conclusion \\n \\n.1 اﯾﻦ ﻗﺴﻤﺖ از ﭼﮑﯿﺪه ﻧﺸﺎن دھﻨﺪه ی ارزش و ﺟﺎﯾﮕﺎه ﺗﺤﻘﯿﻖ ﻣﯽ ﺑﺎﺷﺪ. ﺑﻨﺎﺑﺮاﯾﻦ ﺑﮫ ﻋﻠﺖ ﻋﺪم ﻗﻄﻌﯿﺖ ﻧﻮﯾﺴﻨﺪه از اﻓﻌﺎل \\nﻣﻀﺎرع اﻟﺘﺰاﻣﯽ و ﯾﺎ ﺣﺘﯽ آﯾﻨﺪه ﺑﺎﯾﺪ اﺳﺘﻔﺎده ﮐﻨﺪ. \\n \\n.2 ﺑﯿﺸﺘﺮ آﻧﮑﮫ ﻧﺘﺎﯾﺞ ﻧﻤﺎﯾﻨﺪه ی ﻓﺮﺳﺘﻨﺪه ﻣﯽ ﺑﺎﺷﺪ و ﺟﻤﻊ ﺑﻨﺪی ﻣﺎﻧﻨﺪ ﮔﯿﺮﻧﺪه.flasher ھﺎﯾﯽ ﮐﮫ در اﯾﻨﺠﺎ ﭘﺮ اﺳﺘﻔﺎده ﺧﻮاھﺪ ﺑﻮد \\nﻓﻌﻞ conclude ﯾﺎ contributes ﻣﯽ ﺑﺎﺷﻨﺪ. \\n \\nﻗﺎﻧﻮن ﺷﺸﻢ: ﮐﻠﯿﺖ ﭼﮑﯿﺪه ﺑﺎﯾﺪ ﺑﮫ ﺻﻮرت زﯾﺮ ﺑﺎﺷﺪ:'),\n",
              " Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='ھﺎﯾﯽ ھﺪف ﺗﺤﻘﯿﻖ را ﺑﯿﺎن ﻣﯽ دارد. اﯾﻦflasher \\n ھﺎ ﻣﯽ \\nﺗﻮاﻧﻨﺪ ﺑﮫ ﺻﻮرت زﯾﺮ ﺑﺎﺷﻨﺪ: \\n \\nThis paper presents 1. This paper aims to 2. \\n \\n• روش ﺷﻨﺎﺳﯽ: \\n3ﺑﺎزﮔﻮ ﮐﻨﻨﺪه ﻧﻮآوری ﺧﺎص در ﻣﻘﺎﻟﮫ ﻣﯽ ﺑﺎﺷﺪ. • ﻧﺘﺎﯾﺞ: \\n4ﯾﮑﯽ از ﻣﮭﻢ ﺗﺮﯾﻦ ﻋﻨﺼﺮ ھﺮ ﭼﮑﯿﺪه ﻧﺘﺎﯾﺞ آن ﻣﯽ \\nﺑﺎﺷﺪ ﭼﺮا ﮐﮫ ﻣﺴﺘﻘﯿﻢ ﺗﺮﯾﻦ اﺛﺮ و راﺑﻄﮫ ﺑﺎ ﻋﻨﻮان ﻣﻘﺎﻟﮫ ﻣﯽ ﺑﺎﺷﺪ \\n• ﺟﻤﻊ ﺑﻨﺪی: \\n5در اﯾﻦ ﻋﻨﺼﺮ ﻧﺘﺎﯾﺞ ﻏﯿﺮ ﻣﺴﺘﻘﯿﻢ از ﯾﺎﻓﺘﮫ ھﺎی \\nﻓﻌﻠﯽ و داﻧﺶ را ﺑﺎزﮔﻮ ﻣﯽ ﮐﻨﺪ. \\n \\nﺣﺎل ﮐﮫ ﺑﺎ ﺗﻤﺎﻣﯽ ﻋﻨﺎﺻﺮ ﭼﮑﯿﺪه آﺷﻨﺎ ﺷﺪه اﯾﻢ. ﻣﯽ ﺗﻮاﻧﯿﻢ ﺑﮫ ﻗﻮاﻧﯿﻨﯽ ﮐﮫ از ﻧﻈﺮ ﺑﻨﺪه ﺑﺴﯿﺎر ﻣﮭﻢ ﻣﯽ ﺑﺎﺷﻨﺪ, ﺑﭙﺮدازﯾﻢ. اﯾﻦ ﻗﻮاﻧﯿﻦ'),\n",
              " Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='اﯾﻦ ﻋﻨﺼﺮ Methodology ﺑﯿﺎورد. \\n \\n5 \\nConclusions\\n4 \\nResults\\n3 \\nMethodology\\n2 \\nPurpose\\n1 \\nBackground\\n \\n3 \\n \\n.2 ﻻزم ﺑﮫ ذﮐﺮ اﺳﺖ ﮐﮫ در ﻗﺴﻤﺖ Methodology ﭼﻨﺎﻧﭽﮫ ﻧﻮآوری ﺧﺎص ﺑﺎﺷﺪ اﻏﻠﺐ اﯾﻦ ﻋﻨﺼﺮ ﺑﺎ ﻋﻨﺼﺮ Result ﻋﺠﯿﻦ \\nﺧﻮاھﺪ ﺷﺪ. در اﯾﻦ ﻗﺴﻤﺖ از اﻓﻌﺎل زﻣﺎن ﮔﺬﺷﺘﮫ ﺑﺎﯾﺪ اﺳﺘﻔﺎده ﺷﻮد.'),\n",
              " Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='1.1 ﻣﺠﻤﻮﻋﮫ ﻗﻮاﻧﯿﻦ \\n \\nدر اﯾﻦ ﻗﺴﻤﺖ ﻣﯽ ﺧﻮاھﯿﻢ ﯾﮏ ﻣﺠﻤﻮﻋﮫ ای از ﻗﻮاﻧﯿﻦ ﺗﮭﯿﯿﮫ ﮐﻨﯿﻢ ﮐﮫ ﻣﻄﺎﺑﻖ ﺑﮫ آن ﺑﺘﻮاﻧﯿﻢ ﭼﯿﮑﯿﺪه ﻣﺮﺑﻮط ﺑﮫ ﯾﮏ ﻣﻘﺎﻟﮫ را \\nارزﯾﺎﺑﯽ ﮐﺮد. ﻗﺒﻞ از آﻧﮑﮫ وارد ﻓﺎز ارزﯾﺎﺑﯽ ﺷﻮﯾﻢ ﻣﺮوری ﺑﺮ ﻋﻨﺎﺻﺮ ﭼﮑﯿﺪه را ﺑﺎزﮔﻮ ﺧﻮاھﯿﻢ ﮐﺮد. \\n \\n• زﻣﻨﯿﮫ: \\n1ھﻤﺎﻧﻨﺪ ﮔﺎم اول ﺑﺮایIntroduction \\n ھﺴﺖ ﺑﺎ اﯾﻦ ﺗﻔﺎوت ﮐﮫ در ﭼﮑﯿﺪه ﻣﻘﺎﻟﮫ ﺑﯿﺸﺘﺮ در ﻣﻮرد زﻣﯿﻨﮫ ﺗﺤﻘﯿﻖ ﺻﺤﺒﺖ \\nﺧﻮاھﺪ ﺷﺪ و ﺣﺘﯽ اھﻤﯿﺖ ﻣﻮﺿﻮع ﯾﺎ centeralitiy importance ﻧﯿﺰ ﺻﺤﺒﺖ ﻧﺨﻮاھﺪ ﺷﺪ. \\n \\n• ھﺪف: \\n2در واﻗﻊ در اﯾﻦ ﻋﻨﺼﺮ ﻧﻮﯾﺴﻨﺪه ﺑﺎ اﺳﺘﻔﺎده ازflasher'),\n",
              " Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='.1 ﺑﺎﯾﺪ ﺑﮫ اﯾﻦ ﻧﮑﺘﮫ ﺣﺘﻤﺎ ﺗﻮﺟﮫ ﺷﻮد ﮐﮫ ﺑﮫ ﺻﻮرت ﮐﻠﯽ ﭼﮑﯿﺪه ﺑﺎﯾﺪ ﺑﺪون ﺟﺪول,ﺗﺼﻮﯾﺮ,ﻣﺮﺟﻊ دھﯽ,ارﺟﺎع ﺑﮫ ﺑﺨﺶ ھﺎی ﻣﻘﺎﻟﮫ \\nﺑﺎﺷﺪ. ﭼﺮاﮐﮫ ﺧﻮاﻧﻨﺪه ﻣﻘﺎﻟﮫ ﺻﺮﻓﺎ ﺑﺎ ﺧﻮاﻧﺪن ﭼﮑﯿﺪه ﻣﯽ ﺧﻮاھﺪ ﺗﺼﻤﯿﻢ ﺑﮕﯿﺮد ﮐﮫ ﺑﮫ ﺧﻮاﻧﺪن ﻣﻘﺎﻟﮫ اداﻣﮫ دھﺪ ﯾﺎ ﺧﯿﺮ. ﻓﻠﺬا ﭼﮑﯿﺪه \\nﻣﻘﺎﻻت ﺑﺎﯾﺪ ﻋﺎری از ھﺮﮔﻮﻧﮫ ﺟﺪل و ﺗﺼﻮﯾﺮ و ﻣﺮﺟﻊ دھﯽ ﺑﺎﺷﺪ. \\n \\n.2 ھﻤﯿﻨﻄﻮر ﻣﻌﻤﻮﻻ ﭼﮑﯿﺪه ﻣﻘﺎﻻت ﺑﺎﯾﺪ ﮐﻮﺗﺎه ﺑﺎﺷﻨﺪ در ﺣﺪ دو ﭘﺎراﮔﺮاف ﮐﻔﺎﯾﺖ ﻣﯿﮑﻨﺪ. \\n \\n.3 ﺑﮫ ھﯿﭻ ﻋﻨﻮان ﻧﺒﺎﯾﺪ از ﻗﯿﻮد ﻣﻨﻔﯽ اﺳﺘﻔﺎده ﺷﻮد اﯾﻦ ھﻢ ﺑﮫ دﻟﯿﻞ figural effect ﻣﯽ ﺑﺎﺷﺪ. ﺑﮫ ﻗﻮل اﺳﺘﺎد اﺳﺘﻔﺎده از آن ھﺎ در \\nﭼﮑﯿﺪه ﺣﺮام ﻣﯽ ﺑﺎﺷﺪ!'),\n",
              " Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='ﻗﺴﻤﺖ ﻧﻮﯾﺴﻨﺪه ﺑﺎﯾﺪ از اﻓﻌﺎل زﻣﺎن ﮔﺬﺷﺘﮫ اﺳﺘﻔﺎده ﮐﻨﺪ. ھﻤﯿﻨﻄﻮر اﻏﻠﺐ از flasher ھﺎی زﯾﺮ اﺳﺘﻔﺎده ﻣﯽ ﺷﻮد: \\n \\nshown • indicated • found • \\n \\nﻗﺎﻧﻮن ﭘﻨﺠﻢ:ﻋﻨﺼﺮ آﺧﺮ ﻧﯿﺰ از اھﯿﻤﺖ ﺧﺎﺻﯽ ﺑﺮﺧﻮدار اﺳﺖ. از اﯾﻦ ﺑﺎﺑﺖ ﮐﮫ ﻧﺸﺎن دھﻨﺪه ﻣﮭﺎرت ﻣﺎ در ﻣﻘﺎﻟﮫ ﻧﻮﺷﺘﻦ را ﻣﯽ \\nرﺳﺎﻧﺪ. ﺑﻨﺎﺑﺮاﯾﻦ ﺑﻮدن اﯾﻦ ﻋﻨﺼﺮ ﺣﺎﺋﺰ اھﻤﯿﺖ ﺧﻮاھﺪ ﺑﻮد. ﺑﻌﻀﺎ ﺑﺮﺧﯽ از ﻧﻮﯾﺴﻨﺪه ھﺎی ﻣﻘﺎﻻت اﯾﻦ را ﺑﺎ ﺑﺨﺶ ﻗﺒﻠﯽ ﺑﮫ اﺷﺘﺒﺎه \\nﻣﯿﮕﯿﺮن و ﺑﺎﯾﺪ ﺑﮫ اﯾﻦ ﻧﮑﺘﮫ ﺗﻮﺟﮫ ﮐﻨﻦ ﮐﮫ در اﯾﻦ ﻗﺴﻤﺖ ﭼﮑﯿﺪه ﺑﺎﯾﺪ ﺑﺎ اﺳﺘﻔﺎده از ﻧﺘﺎﯾﺞ ﻗﺴﻤﺖ ﻗﺒﻞ و داﻧﺶ ﻗﺒﻠﯽ در'),\n",
              " Document(metadata={'source': '/content/ruleset.pdf', 'file_path': '/content/ruleset.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'macOS Version 12.2.1 (Build 21D62) Quartz PDFContext', 'creationDate': \"D:20240821102145Z00'00'\", 'modDate': \"D:20240821102145Z00'00'\", 'trapped': ''}, page_content='ﻗﺎﻧﻮن ﭼﮭﺎرم: ﻣﮭﻢ ﺗﺮﯾﻦ ﺑﺨﺶ ﯾﮏ ﻣﻘﺎﻟﮫ ﻋﻨﺼﺮ ﻣﺮﺑﻮط ﺑﮫ ﻧﺘﺎﯾﺞ ﯾﺎ Result ﻣﯽ ﺑﺎﺷﺪ. .1 ﺑﮫ ﻧﻈﺮ ﺑﻨﺪه و آﻧﭽﮫ ﮐﮫ ﺳﺮ ﮐﻼس \\nﺗﻮﺳﻂ اﺳﺘﺎد ﺗﺪرﯾﺲ ﺷﺪه اﺳﺖ اﮔﺮ ﻣﻘﺎﻟﮫ ای اﯾﻦ ﻋﻨﺼﺮ را ﻧﺪاﺷﺘﮫ ﺑﺎﺷﺪ ارزﺷﯽ ﺑﺮای ﺧﻮاﻧﺪن آن ﻣﻘﺎﻟﮫ \\n \\nوﺟﻮد ﻧﺨﻮاھﺪ داﺷﺖ. ﭼﺮا ﮐﮫ ﻣﮭﻢ ﺗﺮﯾﻦ ﯾﺎﻓﺘﮫ ھﺎﯾﯽ ﮐﮫ ﻣﻘﺎﻟﮫ دارد در اﯾﻦ ﺑﺨﺶ ﻣﯽ ﺑﺎﺷﺪ.ﺣﺎل اﮔﺮ اﯾﻦ ﺑﺨﺶ ﺗﻮ ﻣﻘﺎﻟﮫ ﻧﺒﻮد ﭼﺮا \\nﺑﺎﯾﺪ ﺑﮫ ﺧﻮد زﺣﻤﺖ ﺧﻮاﻧﺪن آن ﻣﻘﺎﻟﮫ را دھﯿﻢ. \\n \\n.2 ﯾﮑﯽ دﯾﮕﺮ از ﻧﮑﺎﺗﯽ ﮐﮫ ﺣﺎﺋﺰ اھﻤﯿﺖ ھﺴﺖ ﻣﺴﺘﻘﯿﻢ ﺗﺮﯾﻦ اﺛﺮ و راﺑﻄﮫ ﺑﺎ ﻋﻨﻮان ﻣﻘﺎﻟﮫ را در اﯾﻦ ﺑﺨﺶ ﺧﻮاھﯿﻢ دﯾﺪ. در اﯾﻦ')]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example usage of retrieving documents which demonstrates that it does work with Farsi data\n",
        "\n",
        "query = \"abstract\"\n",
        "\n",
        "retrieved_results = retriever.get_relevant_documents(query)\n",
        "retrieved_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOqG_udlUsCC"
      },
      "source": [
        "### model initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3qOGbWITh1L"
      },
      "outputs": [],
      "source": [
        "llm = ChatTogether(\n",
        "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
        "    temperature= 0\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCoeOkMUUz6n"
      },
      "source": [
        "first step: generating a grading system to grade the given abstracts with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E5sREbzThyX"
      },
      "outputs": [],
      "source": [
        "generate_system_template = (\n",
        "    \"you are a professional reviewer.\"\n",
        "    \"you are asked to evaluate a written abstract of an article based on a ruleset.\"\n",
        "    \"based on the given ruleset, propose a grading system.\"\n",
        "    \"the total grade should sum up to 20.\"\n",
        "    \"ruleset: {ruleset}\"\n",
        ")\n",
        "generate_system_prompt = ChatPromptTemplate.from_template(generate_system_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44s3g9VTVYcr"
      },
      "outputs": [],
      "source": [
        "generate_system_chain = generate_system_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9CRhczFVcu6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "b3b3ba8f-14b3-4df1-e0ed-877c0b157b28"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8193. Given: 8602 `inputs` tokens and 1 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-51eb4403ebc9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m grade_system = generate_system_chain.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m\"ruleset\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     }\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         return cast(\n\u001b[1;32m    276\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    776\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         flattened_outputs = [\n\u001b[1;32m    636\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 results.append(\n\u001b[0;32m--> 624\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    625\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    847\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    666\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    667\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    669\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         )\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 937\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8193. Given: 8602 `inputs` tokens and 1 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}"
          ]
        }
      ],
      "source": [
        "grade_system = generate_system_chain.invoke(\n",
        "    {\n",
        "        \"ruleset\": documents,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w2TnIfvVlvZ",
        "outputId": "0e043b4b-f1a6-4168-a3b7-1965dfdc0597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided ruleset, I propose a grading system to evaluate the written abstract. The total grade will sum up to 20.\n",
            "\n",
            "**Grading Criteria:**\n",
            "\n",
            "1. **Location and Structure** (2 points):\n",
            "\t* Is the abstract located at the beginning of the article?\n",
            "\t* Does the abstract follow the recommended structure (background, purpose, methodology, results, and conclusion)?\n",
            "2. **Keywords and Phrasing** (2 points):\n",
            "\t* Are the provided keywords incorporated naturally into the abstract?\n",
            "\t* Is the language concise, clear, and free of negative verbs and jargon?\n",
            "3. **Instructive and Brief** (2 points):\n",
            "\t* Does the abstract accurately reflect the content of the article?\n",
            "\t* Is the abstract brief and within the recommended word limit (100-125 words)?\n",
            "4. **Self-Sufficient** (2 points):\n",
            "\t* Is the abstract understandable on its own, without referring the reader to the full article?\n",
            "\t* Are undefined terms or acronyms avoided?\n",
            "5. **Clear and Well-Written** (2 points):\n",
            "\t* Is the language engaging and informative?\n",
            "\t* Are strong verbs and active voice used throughout the abstract?\n",
            "6. **Background and Purpose** (2 points):\n",
            "\t* Is the background section present and well-written?\n",
            "\t* Is the purpose of the article clearly stated?\n",
            "7. **Methodology and Results** (2 points):\n",
            "\t* Is the methodology section present and well-written?\n",
            "\t* Are the results clearly stated and focused on facts and research findings?\n",
            "8. **Conclusion** (2 points):\n",
            "\t* Is the conclusion section present and well-written?\n",
            "\t* Does the conclusion summarize the significance of the research and its implications?\n",
            "9. **Overall Coherence and Flow** (2 points):\n",
            "\t* Is the abstract well-organized and easy to follow?\n",
            "\t* Are the transitions between sections smooth and logical?\n",
            "\n",
            "**Grading Scale:**\n",
            "\n",
            "* 18-20: Excellent abstract that meets all the criteria.\n",
            "* 15-17: Good abstract that meets most of the criteria, with some minor improvements needed.\n",
            "* 12-14: Fair abstract that meets some of the criteria, with significant improvements needed.\n",
            "* 0-11: Poor abstract that does not meet the criteria.\n",
            "\n",
            "By using this grading system, you can evaluate the written abstract based on its structure, content, and overall quality.\n"
          ]
        }
      ],
      "source": [
        "print(grade_system)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNAm4pttWCx9"
      },
      "source": [
        "second step: score the abstracts with the grading system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKvEYf1rVpXo"
      },
      "outputs": [],
      "source": [
        "generate_grade_template = (\n",
        "    \"you are a professional reviewer.\"\n",
        "    \"you are asked to evaluate a written abstract of an article based on the following ruleset.\"\n",
        "    \"based on the given grading system grade the given abstract.\"\n",
        "    \"be super strict. They will either get all the points of each section, or they get none of it\"\n",
        "    \"grading_system: {grading_system}\"\n",
        "    \"abstract: {abstract}\"\n",
        ")\n",
        "generate_grade_prompt = ChatPromptTemplate.from_template(generate_grade_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoofjAp9W1np"
      },
      "outputs": [],
      "source": [
        "generate_grade_chain = generate_grade_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cshQEcYqW7Z7"
      },
      "source": [
        "the abstract to be evaluated is now defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_WjB29oW5Mg"
      },
      "outputs": [],
      "source": [
        "abstract = \"\"\"\n",
        "Recent advancements in large language models (LLMs) on language modeling and emergent capabilities make them a promising reference-free evaluator of nat- ural language generation quality, and a competent alternative to human evaluation. However, hindered by the closed-source or high computational demand to host and tune, there is a lack of practice to further calibrate an off-the-shelf LLM-based evaluator towards better human alignment. In this work, we propose AUTOCALI- BRATE, a multi-stage, gradient-free approach to automatically calibrate and align an LLM-based evaluator toward human preference. Instead of explicitly model- ing human preferences, we first implicitly encompass them within a set of human labels. Then, an initial set of scoring criteria is drafted by the language model itself, leveraging in-context learning on different few-shot examples. To further calibrate this set of criteria, we select the best performers and re-draft them with self-refinement. Our experiments on multiple text quality evaluation datasets il- lustrate a significant improvement in correlation with expert evaluation through calibration. Our comprehensive qualitative analysis conveys insightful intuitions and observations on the essence of effective scoring criteria.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc5RJda-XJv8"
      },
      "outputs": [],
      "source": [
        "grade = generate_grade_chain.invoke(\n",
        "    {\n",
        "        \"grading_system\": grade_system,\n",
        "        \"abstract\": abstract\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRJVYH3bXM2H",
        "outputId": "bfd13a19-8273-449e-dcaa-1b4a11f81496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will evaluate the abstract based on the provided grading system. Here's my assessment:\n",
            "\n",
            "**Location and Structure** (2 points): 2 points\n",
            "The abstract is located at the beginning of the article, and it follows the recommended structure (background, purpose, methodology, results, and conclusion).\n",
            "\n",
            "**Keywords and Phrasing** (2 points): 2 points\n",
            "The provided keywords (e.g., \"large language models\", \"natural language generation quality\", \"human alignment\") are incorporated naturally into the abstract. The language is concise, clear, and free of negative verbs and jargon.\n",
            "\n",
            "**Instructive and Brief** (2 points): 2 points\n",
            "The abstract accurately reflects the content of the article, and it is brief and within the recommended word limit (100-125 words).\n",
            "\n",
            "**Self-Sufficient** (2 points): 2 points\n",
            "The abstract is understandable on its own, without referring the reader to the full article. Undefined terms or acronyms are avoided.\n",
            "\n",
            "**Clear and Well-Written** (2 points): 2 points\n",
            "The language is engaging and informative. Strong verbs and active voice are used throughout the abstract.\n",
            "\n",
            "**Background and Purpose** (2 points): 2 points\n",
            "The background section is present and well-written, providing context for the research. The purpose of the article is clearly stated.\n",
            "\n",
            "**Methodology and Results** (2 points): 2 points\n",
            "The methodology section is present and well-written, describing the approach used. The results are clearly stated and focused on facts and research findings.\n",
            "\n",
            "**Conclusion** (2 points): 2 points\n",
            "The conclusion section is present and well-written, summarizing the significance of the research and its implications.\n",
            "\n",
            "**Overall Coherence and Flow** (2 points): 2 points\n",
            "The abstract is well-organized and easy to follow. The transitions between sections are smooth and logical.\n",
            "\n",
            "**Total Grade: 20**\n",
            "\n",
            "Based on the grading system, I would give this abstract an **Excellent** score (18-20). The abstract meets all the criteria, and it is well-written, clear, and concise. It effectively conveys the research's purpose, methodology, results, and significance, making it an excellent representation of the article.\n"
          ]
        }
      ],
      "source": [
        "print(grade)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqKU87hhXjsQ"
      },
      "source": [
        "another example where the abstract does not have the results section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEaexsdhXRuW"
      },
      "outputs": [],
      "source": [
        "abstract = \"\"\"\n",
        "Recent advancements in large language models (LLMs) on language modeling and emergent capabilities make them a promising reference-free evaluator of nat- ural language generation quality, and a competent alternative to human evaluation. However, hindered by the closed-source or high computational demand to host and tune, there is a lack of practice to further calibrate an off-the-shelf LLM-based evaluator towards better human alignment. In this work, we propose AUTOCALI- BRATE, a multi-stage, gradient-free approach to automatically calibrate and align an LLM-based evaluator toward human preference. Instead of explicitly model- ing human preferences, we first implicitly encompass them within a set of human labels. Then, an initial set of scoring criteria is drafted by the language model itself, leveraging in-context learning on different few-shot examples. To further calibrate this set of criteria, we select the best performers and re-draft them with self-refinement.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqDGhYdSX0A2",
        "outputId": "5a91e579-fad2-4207-b022-a8a98fd2f2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will evaluate the abstract based on the provided grading system. Here's my assessment:\n",
            "\n",
            "**Location and Structure** (2 points): 2 points\n",
            "The abstract is located at the beginning of the article, and it follows the recommended structure (background, purpose, methodology, and results).\n",
            "\n",
            "**Keywords and Phrasing** (2 points): 2 points\n",
            "The abstract incorporates keywords like \"large language models,\" \"natural language generation quality,\" and \"human alignment\" naturally. The language is concise and clear, with no negative verbs or jargon.\n",
            "\n",
            "**Instructive and Brief** (2 points): 2 points\n",
            "The abstract accurately reflects the content of the article, and it is brief, within the recommended word limit (100-125 words).\n",
            "\n",
            "**Self-Sufficient** (2 points): 2 points\n",
            "The abstract is understandable on its own, without referring the reader to the full article. Undefined terms or acronyms are avoided.\n",
            "\n",
            "**Clear and Well-Written** (2 points): 2 points\n",
            "The language is engaging and informative, with strong verbs and active voice used throughout the abstract.\n",
            "\n",
            "**Background and Purpose** (2 points): 2 points\n",
            "The background section is present and well-written, providing context for the research. The purpose of the article is clearly stated.\n",
            "\n",
            "**Methodology and Results** (2 points): 2 points\n",
            "The methodology section is present and well-written, describing the approach used. The results are clearly stated, focusing on facts and research findings.\n",
            "\n",
            "**Conclusion** (2 points): 0 points\n",
            "There is no conclusion section in the abstract, which is a significant omission.\n",
            "\n",
            "**Overall Coherence and Flow** (2 points): 2 points\n",
            "The abstract is well-organized and easy to follow, with smooth transitions between sections.\n",
            "\n",
            "Total score: 16 points\n",
            "\n",
            "Based on the grading scale, I would rate this abstract as \"Good\" (15-17 points), as it meets most of the criteria, with some minor improvements needed. The main area for improvement is the lack of a conclusion section, which is a critical component of an abstract.\n"
          ]
        }
      ],
      "source": [
        "grade = generate_grade_chain.invoke(\n",
        "    {\n",
        "        \"grading_system\": grade_system,\n",
        "        \"abstract\": abstract\n",
        "    }\n",
        ")\n",
        "print(grade)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}